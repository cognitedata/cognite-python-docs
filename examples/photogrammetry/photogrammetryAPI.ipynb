{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photogrammetry API\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "<b>The Photogrammetry API is highly experimental and some features may not be available or function correctly at the moment. Please use this API with care, as we issue no guarantees this API won't break.\n",
    "</b> \n",
    "</div>\n",
    "\n",
    "In this tutorial we will go through how to use Cognite's Photogrammetry API to create contextualised 3D models using images.\n",
    "\n",
    "The API reference is available here: [https://doc.cognitedata.com/api/playground/](https://doc.cognitedata.com/api/playground/)\n",
    "\n",
    "\n",
    "### Background\n",
    "\n",
    "In order to create contextualised 3D models we have developed a pipeline with several modular parts. First, images are uploaded as a zip file by the user. These images go through a quality control step, where low quality images (blurry) are filtered out. Next, the 3D reconstruction and tag detection steps are started. The former is done by using a method called photogrammetry, which uses overlapping images from a real-world object or scene to create a 3D model.\n",
    "\n",
    "The tag detection is done in two steps. First we use Convolution Neural Networks (CNN) for detection of tags, and thereafter optical character recognition (OCR) is used for recognizing the tag text. In the last step, the image pixel coordinates extracted by the tag detector are mapped to 3D locations.\n",
    "\n",
    "\n",
    "<img src=\"images/pipeline.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step example\n",
    "\n",
    "The photogrammetry API is currently only enabled for a few selected tenants, including **mltest**. If you want access from other tenants, please contact us via the **#ml-vision** Slack channel or open a pull request in this repo.\n",
    "\n",
    "First, we make the imports we'll need for this tutorial and use an API key to authenticate. Make sure that you have first set the API key as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from cognite.client import CogniteClient\n",
    "from cognite.client.stable.assets import Asset\n",
    "\n",
    "BASEURL = \"/api/playground/vision\"\n",
    "os.environ[\"COGNITE_DISABLE_GZIP\"] = \"1\"\n",
    "client = CogniteClient(api_key=os.environ['COGNITE_API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Photogrammetry models\n",
    "\n",
    "List all available Photogrammetry models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = client.get(url=f\"{BASEURL}/photogrammetry\").json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add assets to your Tenant\n",
    "\n",
    "When contextualising the 3D model, we compare the detected tags suggested by the model, with actual asset tags obtained from either the assets in the current tenant or provided as an argument. If the current tenant does not have the asset you want to detect, you can add it using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_asset(client, name):\n",
    "    my_asset = Asset(name)\n",
    "    assets_to_post = [my_asset]\n",
    "    response = client.assets.post_assets(assets_to_post)\n",
    "    \n",
    "#add_asset(client, \"50CX0001A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Photogrammetry model\n",
    "\n",
    "To create a Photogrammetry model you need to provide the `name` field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"my_contextualised_model\" # Your model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to contextualise the model (i.e. detect tags), you also have to set contextualise to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualise_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When contextualising a model, our service will detect tag ids which are compared against either a provided list of tag ids, or existing tags in the current tenant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_photogrammetry_model(client, name, contextualise=False, tag_list=None):\n",
    "    response = client.post(\n",
    "        url= f\"{BASEURL}/photogrammetry\",\n",
    "        body={\"name\": name, \"contextualise\": contextualise, \"tagList\": tag_list}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Option 1) without contextualisation:\n",
    "# photogrammetry_model = create_photogrammetry_model(client, name)\n",
    "\n",
    "# Option 2) contextualisation from assets in the tenant:\n",
    "# photogrammetry_model = create_photogrammetry_model(client, name, contextualise=contextualise_model) \n",
    "\n",
    "# Option 3) contextualisation from tag_list\n",
    "photogrammetry_model = create_photogrammetry_model(client,\n",
    "                                                   name, \n",
    "                                                   contextualise=contextualise_model, \n",
    "                                                   tag_list=\"['50CX0001A']\")\n",
    "photogrammetry_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve information about single a Photogrammetry model\n",
    "\n",
    "Returns info about a specific photogrammetry model. Takes model id as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{BASEURL}/photogrammetry/{photogrammetry_model['id']}\"\n",
    "response = client.get(url=url).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload images\n",
    "\n",
    "To upload images, you need to provide the upload url for the Photogrammetry model and the filepath for the zip file containing the images. The reconstruction will start immediately after the upload. We have created a test dataset, which you can download from [here](https://drive.google.com/open?id=1VaIURFCuv0BT2ny_-wcz6Kucayj5qkIk) or you can use your own images (*remember to change the zip file path!*). \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>\n",
    "    \n",
    "* The supported image formats are: jpeg, jpg, jpe, and png.\n",
    "    \n",
    "    \n",
    "* The maximum number of images you can have in a model is 300.\n",
    "\n",
    "\n",
    "* Maximum size of a single image: 128 MB \n",
    "</b></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_images(upload_url, zip_file_path):\n",
    "    import requests\n",
    "    headers = {\"content-length\": str(os.path.getsize(zip_file_path))}\n",
    "    \n",
    "    with open(zip_file_path, \"rb\") as file:\n",
    "        requests.put(upload_url, data=file, headers=headers)\n",
    "        \n",
    "zip_file_path = \"path/to/zipfile.zip\" # CHANGE ME! \n",
    "\n",
    "upload_images(photogrammetry_model[\"uploadUrl\"], zip_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the 3D file and Tag locations\n",
    "\n",
    "To check whether your 3D model is ready, use `photogrammetry_model_info()` to see if the photogrammetry job is finished. If that is the case, `status` will be `SUCCESS` and you get a download URL link that can be used to download the 3D file (fbx file). The detected tags and their 3D location will be part of the response. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><b>\n",
    "It takes around 15-20 minutes to process and create a 3D model using the dataset provided above.\n",
    "</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"output.fbx\"\n",
    "url = f\"{BASEURL}/photogrammetry/{photogrammetry_model['id']}\"\n",
    "response = client.get(url=url).json()\n",
    "\n",
    "\n",
    "if response[\"status\"] == \"SUCCESS\":\n",
    "    download_url = response[\"download_url\"]\n",
    "    urlretrieve(download_url, output_filename)\n",
    "    \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the photogrammetry model\n",
    "\n",
    "To avoid crowding it might be a good idea to remove old/unused photogrammetry models. Currently this can be done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{BASEURL}/photogrammetry/{photogrammetry_model['id']}\"\n",
    "response = client.delete(url=url).json()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "\n",
    "\n",
    "* [Autodesk ReMake - How to Take Photos for Photogrammetry](https://www.youtube.com/watch?v=D7Torjkfec4)\n",
    "\n",
    "* [The Art of Photogrammetry: How To Take Your Photos](https://www.tested.com/art/makers/460142-art-photogrammetry-how-take-your-photos/)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
